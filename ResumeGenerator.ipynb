{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219b332f-51b6-4de4-aa97-b6832adb55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, json, csv, os, re\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd74c52-c348-44b6-82e9-b072e6893c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matto\\anaconda3\\envs\\words\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "def run_js_generator(json_path: str) -> dict:\n",
    "    \"\"\"Run the Node.js generator and parse its JSON output.\"\"\"\n",
    "    js_script = \"generate_resume.js\"\n",
    "    result = subprocess.run(\n",
    "        [\"node\", str(js_script), json_path],\n",
    "        capture_output=True, text=True, encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"JS Generator stderr:\", result.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # The JS script prints status lines and then a JSON object on the last line\n",
    "    lines = result.stdout.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if not line.startswith(\"{\"):\n",
    "            print(line)  # Print status messages (e.g. \"‚úì DOCX written: ...\")\n",
    "\n",
    "    # Parse the JSON output (last line)\n",
    "    try:\n",
    "        output_info = json.loads(lines[-1])\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse JS generator output.\")\n",
    "        print(\"Full stdout:\", result.stdout)\n",
    "        sys.exit(1)\n",
    "\n",
    "    return output_info\n",
    "\n",
    "from docx2pdf import convert\n",
    "\n",
    "def convert_to_pdf(docx_path):\n",
    "    \"\"\"Convert DOCX to PDF using docx2pdf. PDFs go to output/, not output/docx files/.\"\"\"\n",
    "    pdf_path = str(Path(docx_path).parent.parent / Path(docx_path).stem) + \".pdf\"\n",
    "    convert(docx_path, pdf_path, keep_active=True)\n",
    "    print(f\"‚úì PDF written: {pdf_path}\")\n",
    "    return pdf_path\n",
    "    \n",
    "\n",
    "def update_tracker(data: dict, docx_path: str, pdf_path: str):\n",
    "    \"\"\"Append a row to tracker.csv.\"\"\"\n",
    "    tracker_path = Path(\"tracker.csv\")\n",
    "\n",
    "    # Read existing content to check if header exists\n",
    "    file_exists = tracker_path.exists() and tracker_path.stat().st_size > 0\n",
    "\n",
    "    row = {\n",
    "        \"date\": data[\"metadata\"].get(\"date_applied\", datetime.now().strftime(\"%Y-%m-%d\")),\n",
    "        \"company\": data[\"metadata\"].get(\"target_company\", \"\"),\n",
    "        \"role\": data[\"metadata\"].get(\"target_role\", \"\"),\n",
    "        \"status\": data[\"metadata\"].get(\"status\", \"draft\"),\n",
    "        \"resume_file\": os.path.basename(docx_path),\n",
    "        \"cover_letter_file\": \"yes\" if (data.get(\"cover_letter\") and data[\"cover_letter\"].get(\"opening\")) else \"no\",\n",
    "        \"notes\": data[\"metadata\"].get(\"notes\", \"\")\n",
    "    }\n",
    "\n",
    "    with open(tracker_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "    print(f\"‚úì Tracker updated: {tracker_path}\")\n",
    "\n",
    "def expected_output_exists(data: dict) -> bool:\n",
    "    \"\"\"Mirror the JS filename logic to check if this application has already been generated.\"\"\"\n",
    "    name = data[\"header\"][\"name\"].split(\",\")[0].strip()\n",
    "    company = re.sub(r'[^a-zA-Z0-9 ]', '', data[\"metadata\"][\"target_company\"]).strip()\n",
    "    role = re.sub(r'[^a-zA-Z0-9 ]', '', data[\"metadata\"][\"target_role\"]).strip()\n",
    "    base = f\"{name}_{company}_{role}\"\n",
    "    return Path(\"output\", \"docx files\", f\"{base}_resume.docx\").exists()\n",
    "\n",
    "\n",
    "def generate_all():\n",
    "    app_dir = Path(\"applications\")\n",
    "    json_files = sorted(app_dir.glob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(\"No JSON files found in applications/\")\n",
    "        return\n",
    "\n",
    "    pending, skipped = [], []\n",
    "\n",
    "    for json_path in json_files:\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if expected_output_exists(data):\n",
    "            skipped.append(json_path.name)\n",
    "            continue\n",
    "\n",
    "        pending.append((json_path, data))\n",
    "\n",
    "    print(f\"\\nüìä Found {len(json_files)} application(s): {len(pending)} to generate, {len(skipped)} already done.\\n\")\n",
    "\n",
    "    if skipped:\n",
    "        print(f\"  ‚è≠Ô∏è  Skipping: {', '.join(skipped)}\\n\")\n",
    "\n",
    "    for json_path, data in pending:\n",
    "        print(f\"üìÑ Generating: {json_path.name}\")\n",
    "\n",
    "        output_info = run_js_generator(str(json_path))\n",
    "        docx_path = output_info[\"docx\"]\n",
    "        pdf_path = convert_to_pdf(docx_path)\n",
    "\n",
    "        if output_info.get(\"coverLetterDocx\"):\n",
    "            convert_to_pdf(output_info[\"coverLetterDocx\"])\n",
    "\n",
    "        update_tracker(data, docx_path, pdf_path)\n",
    "        print(f\"  ‚úÖ Done.\\n\")\n",
    "\n",
    "    print(f\"‚úÖ All {len(pending)} resume(s) generated.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "709f98ff-034a-4136-b26f-db6148fce16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Found 43 application(s): 3 to generate, 40 already done.\n",
      "\n",
      "  ‚è≠Ô∏è  Skipping: 2026-02-01_1password_vp-data-analytics.json, 2026-02-01_actblue_director-engineering-data-science.json, 2026-02-01_apogee-therapeutics_director-data-engineering-analytics.json, 2026-02-01_hello-heart_director-analytics.json, 2026-02-01_incyte_machine-learning-engineer.json, 2026-02-01_supercom_director-analytics-data-science.json, 2026-02-01_symetra_avp-data-analytics.json, 2026-02-01_test-company_senior-data-scientist.json, 2026-02-02_alimentiv_director-enterprise-data.json, 2026-02-02_amgen_responsible-ai-manager.json, 2026-02-02_biogen_director-advanced-analytics-data-science-ai.json, 2026-02-02_danaher_senior-director-ai-data-infrastructure.json, 2026-02-02_insulet_director-data-biostatistics.json, 2026-02-02_natera_director-data-ai-governance.json, 2026-02-02_veeva-systems_senior-director-engineering-data-operations.json, 2026-02-03_bridgeview_director-data-analytics.json, 2026-02-03_mckesson_director-data-governance.json, 2026-02-03_point_head-of-data.json, 2026-02-03_salesforce_sr-director-enterprise-data-governance.json, 2026-02-03_smarterdx_director-data-science.json, 2026-02-04_duetto_vp-data-science.json, 2026-02-04_eli-lilly_senior-risk-analytics-leader.json, 2026-02-04_hca-healthcare_director-data-science.json, 2026-02-04_lumen_senior-ai-leader.json, 2026-02-04_pharma-fsp_ad-ai-innovative-solutions.json, 2026-02-04_quest_senior-director-machine-learning.json, 2026-02-04_senior-ml-engineer.json, 2026-02-04_sentara_senior-data-governance-analyst.json, 2026-02-04_surgery-partners_senior-director-data-product.json, 2026-02-06_beone_senior-director-data-insight.json, 2026-02-09_apei_director-data-management-governance.json, 2026-02-09_ucb_global-head-data-evaluation-enablement.json, 2026-02-11_legends-global_senior-director-ai-insights.json, 2026-02-11_symphonyai_director-data-science-predictive-agentic-ai.json, 2026-02-11_zayzoon_director-of-data.json, 2026-02-12_lrn_director-ai-data-science.json, 2026-02-13_enzo_director_data_analytics.json, 2026-02-17_compliance-insights_regulatory-data-science-analytics.json, 2026-02-18_indegene_director-medical-analytics.json, 2026-02-21_bmo_director-enterprise-data-management.json\n",
      "\n",
      "üìÑ Generating: 2026-02-23_alignment-health_director-data-science.json\n",
      "‚úì DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_Alignment Health_Director of Data Science_resume.docx\n",
      "‚úì Cover letter DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_Alignment Health_Director of Data Science_cover_letter.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_Alignment Health_Director of Data Science_resume.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_Alignment Health_Director of Data Science_cover_letter.pdf\n",
      "‚úì Tracker updated: tracker.csv\n",
      "  ‚úÖ Done.\n",
      "\n",
      "üìÑ Generating: 2026-02-23_dynatron_sr-director-data.json\n",
      "‚úì DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_Dynatron_Sr Director of Data_resume.docx\n",
      "‚úì Cover letter DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_Dynatron_Sr Director of Data_cover_letter.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_Dynatron_Sr Director of Data_resume.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_Dynatron_Sr Director of Data_cover_letter.pdf\n",
      "‚úì Tracker updated: tracker.csv\n",
      "  ‚úÖ Done.\n",
      "\n",
      "üìÑ Generating: 2026-02-23_llr-partners_director-ai-strategy-value-creation.json\n",
      "‚úì DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_LLR Partners_Director of AI Strategy  Value Creation_resume.docx\n",
      "‚úì Cover letter DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_LLR Partners_Director of AI Strategy  Value Creation_cover_letter.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_LLR Partners_Director of AI Strategy  Value Creation_resume.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_LLR Partners_Director of AI Strategy  Value Creation_cover_letter.pdf\n",
      "‚úì Tracker updated: tracker.csv\n",
      "  ‚úÖ Done.\n",
      "\n",
      "‚úÖ All 3 resume(s) generated.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5314b38a-c446-4154-88a7-61dc7147f6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Generating resume from: applications\\2026-02-01_test-company_senior-data-scientist.json\n",
      "\n",
      "‚úì DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_Test Company_Senior Data Scientist_resume.docx\n",
      "‚úì Cover letter DOCX written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\docx files\\Matt Oremland_Test Company_Senior Data Scientist_cover_letter.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_Test Company_Senior Data Scientist_resume.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF written: C:\\Users\\matto\\OneDrive\\Python\\resume-generator\\output\\Matt Oremland_Test Company_Senior Data Scientist_cover_letter.pdf\n",
      "‚úì Tracker updated: tracker.csv\n",
      "\n",
      "‚úÖ Done! Files are in: output/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT_JSON = \"2026-02-01_test-company_senior-data-scientist.json\"\n",
    "\n",
    "def generate(json_file):\n",
    "    json_path = os.path.join('applications', json_file)\n",
    "    \n",
    "    if not Path(json_path).exists():\n",
    "        print(f\"Error: File not found: {json_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìÑ Generating resume from: {json_path}\\n\")\n",
    "    \n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Step 1: Generate DOCX(s) via JS\n",
    "    output_info = run_js_generator(json_path)\n",
    "    docx_path = output_info[\"docx\"]\n",
    "    \n",
    "    # Step 2: Convert resume to PDF\n",
    "    pdf_path = convert_to_pdf(docx_path)\n",
    "    \n",
    "    # Step 3: Convert cover letter to PDF if it exists\n",
    "    if output_info.get(\"coverLetterDocx\"):\n",
    "        convert_to_pdf(output_info[\"coverLetterDocx\"])\n",
    "    \n",
    "    # Step 4: Update tracker\n",
    "    update_tracker(data, docx_path, pdf_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Done! Files are in: output/\\n\")\n",
    "\n",
    "generate(INPUT_JSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (words)",
   "language": "python",
   "name": "words"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
